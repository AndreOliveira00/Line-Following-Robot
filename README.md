# Line-Following-Robot
The project in question seeks to develop an implementation of a dynamic and properly autonomous system that promotes the movement of a vehicle with differential wheels according to computational processes allocated to several ROS nodes. The Raspberry Pi 3 on board the vehicle is equipped with a raspicam capable of extracting the various information from the route. The processing of these images must result in a precise actuation in the motors coupled to each wheel.

## Prototype
<p align="center">
<img src="https://user-images.githubusercontent.com/72403325/167471181-b0e6311e-2455-417d-816e-38ccdcce8670.png" data-canonical-src="https://user-images.githubusercontent.com/72403325/167471181-b0e6311e-2455-417d-816e-38ccdcce8670.png" width="699" height="602" />
</p>

## Practical Demonstration of the Prototype
<p align="center">
<img src="/Takes/take_1_agv_map.gif" data-canonical-src="/Takes/take_1_agv_map.gif"
</p>

## Image Processing
<p align="center">
<img src="https://user-images.githubusercontent.com/72403325/167475443-dde1c7c7-882d-44be-9964-44d7e4cf7693.png" data-canonical-src="https://user-images.githubusercontent.com/72403325/167475443-dde1c7c7-882d-44be-9964-44d7e4cf7693.png" width="528" height="395" />
</p>

<p align="center">
<video src="https://user-images.githubusercontent.com/72403325/168483448-1db00691-909e-44eb-9b1f-7b8cd9ce1936.mp4" data-canonical-src="https://user-images.githubusercontent.com/72403325/168483448-1db00691-909e-44eb-9b1f-7b8cd9ce1936.mp4" width="528" height="400" controls="controls" muted="muted" >
</video>
</p>


<p align="center">
<video controls muted src="https://user-images.githubusercontent.com/72403325/168483547-5f3ccd66-37a4-4764-afac-a2a067f34b89.mp4" data-canonical-src="https://user-images.githubusercontent.com/72403325/168483547-5f3ccd66-37a4-4764-afac-a2a067f34b89.mp4" width="528" height="400" muted="muted" >
</video>
</p>









